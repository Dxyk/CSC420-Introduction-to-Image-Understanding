% Template credit to University of Toronto CSC411 and CSC320
%------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{subcaption}
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
% Below are optional packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\chead{\hmwkClass\ : \hmwkTitle} % Top center head
%\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs


%------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
	%\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
	%\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
	%\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
	%\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems
\setcounter{homeworkProblemCounter}{0}

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
	\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
	\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
	\section{\homeworkProblemName} % Make a section in the document with the custom problem count
	\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
	\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
	\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
	\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
	\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
	\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
	\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}


%=================================================================

%------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Assignment\ 2} % Assignment title
\newcommand{\hmwkClass}{CSC420} % Course/class
\newcommand{\hmwkAuthorName}{Xiangyu Kong, kongxi16} % Your name

%------------------------------------------------------------------------------------
%	TITLE PAGE
%------------------------------------------------------------------------------------

\title{
	\vspace{2in}
	\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
	%	\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
	\vspace{0.1in}
	\vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}

% Insert date here if you want it to appear below your name
\date{\today} 

%------------------------------------------------------------------------------------

\begin{document}
	
	\maketitle
	\clearpage
	
	%=========================================================
	%---------------------------------------------------------------------------------
	%	PROBLEM 1: 
	%---------------------------------------------------------------------------------
	%=========================================================
	\begin{homeworkProblem}
		
        See \textit{question\_1.py} for implementation.
        
		\begin{enumerate}
			
			\item 
			
			The result of applying linear interpolation to up-sample the image by 4 times are shown in Figure \ref{fig:1.1}.
            
            Figure \ref{fig:1.1.1} shows the first round of convolution along the first axis. 
            
            Figure \ref{fig:1.1.2} shows the second round of convolution along the second axis on top of the result of the first round.
            
            Comparing to the original image, the up-sampled image maintains most of the information because the images look alike.
            
            \begin{figure}[!htb]
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[height=\linewidth, width=\linewidth]{images/question_1/1_1_1.jpg}
                    \centering
                    \caption{First round}
                    \label{fig:1.1.1}
                \end{subfigure}
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/question_1/1_1_2.jpg}
                    \centering
                    \caption{Second Round}
                    \label{fig:1.1.2}
                \end{subfigure}
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/orig/bee.jpg}
                    \centering
                    \caption{Original Image}
                    \label{fig:1.1.3}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:1.1}
            \end{figure}
        
            To achieve the same operation (up-sampling by a factor of 4), we can multiply the 1-dimensional filter by itself to get a 2-dimensional filter. This filter will be separable, and will produce the same result as convolving with the 1-dimensional filter twice on different directions.
            
            In this specific case of up-sampling by a factor of 4, we calculate that
            
            \begin{align*}
                h & = 
                \begin{bmatrix}
                0.25 & 0.5 & 0.75 & 1 & 0.75 & 0.5 & 0.25
                \end{bmatrix} \\
                h \times h^{T} & = 
                \begin{bmatrix}
                0.0625 & 0.125 & 0.1875 & 0.25 & 0.1875 & 0.125 & 0.0625 \\
                0.125 & 0.25 & 0.375 & 0.5 & 0.375 & 0.25 & 0.125 \\
                0.1875 & 0.375 & 0.5625 & 0.75 & 0.5625 & 0.375 &0.1875\\
                0.25 & 0.5 & 0.75 & 1 &	0.75 & 0.5 & 0.25\\
                0.1875 & 0.375 & 0.5625 & 0.75 & 0.5625 & 0.375 &0.1875\\
                0.125  & 0.25 & 0.375 &	0.5 & 0.375 & 0.25 & 0.125\\
                0.0625 & 0.125 & 0.1875 & 0.25 & 0.1875	& 0.125	& 0.0625
                \end{bmatrix} \\
            \end{align*}

            \newpage
            \item
            
            In the 2d case, the original signal (image) will be a 2D matrix:
            $
            \begin{bmatrix}
            F(0, 0) & F(0, 1) & \dots\\
            F(1, 0) & F(1, 1) & \dots\\
            \vdots & \vdots & \vdots
            \end{bmatrix}
            $
            
            Initializing $G'$:
            $
            \begin{bmatrix}
            F(0, 0) & 0 & 0 & 0 & F(0, 1) & \dots\\
            0 & 0 & 0 & 0 & 0 & \dots\\
            0 & 0 & 0 & 0 & 0 & \dots\\
            0 & 0 & 0 & 0 & 0 & \dots\\
            F(1, 0) & 0 & 0 & 0 & F(1, 1) & \dots\\
            \vdots & \vdots & \vdots & \vdots
            \end{bmatrix}
            $
            
            We want the final matrix's element $G(i, j) = \dfrac{4 - i \% 4}{4} \times F(i // 4, j) + \dfrac{i \% 4}{4} \times F(i // 4 + 1, j) + \dfrac{4 - j \% 4}{4} \times F(j // 4) + \dfrac{j \% 4}{4} \times F(i, j // 4 + 1)$ so that $G(i, j)$ linearly resembles the closest elements in $F(x, y)$.
            
            Thus for 2d quadruple linear interpolation, the filter should be 
            \begin{align*}
            h = 
            \begin{bmatrix}
            0.0625 & 0.125 & 0.1875 & 0.25 & 0.1875 & 0.125 & 0.0625 \\
            0.125 & 0.25 & 0.375 & 0.5 & 0.375 & 0.25 & 0.125 \\
            0.1875 & 0.375 & 0.5625 & 0.75 & 0.5625 & 0.375 &0.1875\\
            0.25 & 0.5 & 0.75 & 1 &	0.75 & 0.5 & 0.25\\
            0.1875 & 0.375 & 0.5625 & 0.75 & 0.5625 & 0.375 &0.1875\\
            0.125  & 0.25 & 0.375 &	0.5 & 0.375 & 0.25 & 0.125\\
            0.0625 & 0.125 & 0.1875 & 0.25 & 0.1875	& 0.125	& 0.0625
            \end{bmatrix}
            \end{align*}
            
            $h(i, j) = a * b$
            where \\
            $a = \dfrac{i}{4}$ if $i < 4$ and $a = \dfrac{8 - i}{4}$ if $i \geq 4$ and \\
            $b = \dfrac{j}{4}$ if $j < 4$ and $b = \dfrac{8 - j}{4}$ if $j \geq 4$
            
            Generalizing to two dimensional linear interpolation for any $d$, the reconstruction filter is 
            
            
            \begin{align*}
            h & = 
            \begin{bmatrix}
            \frac{1}{d} & \dots & \frac{d-1}{d} & 1 & \frac{d-1}{d} & \dots & \frac{1}{d}
            \end{bmatrix} \\
            h \times h^{T} & = 
            \begin{bmatrix}
            \frac{1}{d}^2 & \dots & \frac{d-1}{d} \times \frac{1}{d} & 1 \times \frac{1}{d} & \frac{d-1}{d} \times \frac{1}{d} & \dots & \frac{1}{d}^2 \\
            \frac{d-1}{d} \times \frac{1}{d} & \ddots & \dots & \dots & \dots & \dots & \vdots \\
            \vdots & \dots & \dots & 1 &	\dots & \dots & \vdots\\
            \frac{d-1}{d} \times \frac{1}{d} & \dots & \dots & \dots & \dots	& \dots	& \frac{d-1}{d}^2
            \end{bmatrix} \\
            \end{align*}
            
            Since this is a separable filter (composed of $h \times h^T$), it is equivalent of applying the 1D linear interpolation filter twice in both direction.
            
            The results of the 2D linear interpolation filter convolution is shown in Figure \ref{fig:1.2.1}. Comparing to the result of applying 1D linear interpolation filter twice in two directions (Figure \ref{fig:1.2.2}), the results do not have any difference. 
            
            \begin{figure}[!htb]
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/question_1/1_2.jpg}
                    \centering
                    \caption{2D Filter}
                    \label{fig:1.2.1}
                \end{subfigure}
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/question_1/1_1_2.jpg}
                    \centering
                    \caption{1D Filter}
                    \label{fig:1.2.2}
                \end{subfigure}
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/orig/bee.jpg}
                    \centering
                    \caption{Original Image}
                    \label{fig:1.2.3}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:1.2}
            \end{figure}
			
		\end{enumerate}
	
	\end{homeworkProblem}

    \clearpage
    %=========================================================
    %---------------------------------------------------------------------------------
    %	PROBLEM 2: 
    %---------------------------------------------------------------------------------
    %=========================================================
    \begin{homeworkProblem}
    	
        See \textit{question\_2.py} for implementations.
        
    	\begin{enumerate}
    		\item
            The outputs of the corner detection functions are listed in Figure \ref{fig:2.1}.
            
            After tuning with different alpha values, $\alpha = 0.06$ was picked because it produced the least amount of noise.
            
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_1_Harris.jpg}
                \centering
                \caption{Harris corner detection}
                \label{fig:2.1.1}
            \end{figure}
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_1_Brown.jpg}
                \centering
                \caption{Brown corner detection}
                \label{fig:2.1.2}
            \end{figure}
            
            The only way for us to calculate the R scores without using determinant or trace is to calculate the eigenvalues for each window's error term. However, this is extremely computationally heavy and does yield a better result than computing the trace and determinant.
            
            \item
            
            First we rotate the original image to produce Figure \ref{fig:2.2.1}
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_2/2_2_rotated_img.jpg}
                    \centering
                    \caption{Rotated image}
                    \label{fig:2.2.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_2/2_2_orig_img.jpg}
                    \centering
                    \caption{Original Image}
                    \label{fig:2.2.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:2.2}
            \end{figure}
        
            By applying Harris corner detection to the rotated image, we get Figure \ref{fig:2.2.3}. We can see that the detected corners are also rotated.
        
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_2_rotated_R.jpg}
                \centering
                \caption{Rotated Haris corner detection}
                \label{fig:2.2.3}
            \end{figure}
            
            \newpage
        
            By rotating the detected corners, we get the following Figure \ref{fig:2.2.4}.
            
            To prove that the detected points are also rotated by the same angle, we count the number of detected corners in the rotated image ($num\_total\_rotated$). Then we also count the number of corners in the original image corresponding to the corners in the rotated image ($num\_match$). Then we take the fraction of those two $\dfrac{num\_match}{num\_total\_rotated}$. The result was $99\%$ which is sufficient to prove that the detected corners are the same.
            
            Note that we didn't count the total number of detected corner in the original image ($num\_total\_original$) and compare it with the number of corners detected in the rotated image because rotating the image will caused some information loss, and this measurement won't be accurate.
            
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_2_rerotated_R.jpg}
                \centering
                \caption{Un-rotate detected corners}
                \label{fig:2.2.4}
            \end{figure}
        
            \newpage
            \item 
            The interest points are shown bellow
            
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_3_interest_points.jpg}
                \centering
                \caption{Interest points}
                \label{fig:2.3.1}
            \end{figure}
        
            By circling out the interest points on the original image, we get Figure \ref{fig:2.3.21}.
            
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_3_result.jpg}
                \centering
                \caption{Image with interest points}
                \label{fig:2.3.21}
            \end{figure}
        
            We can see that the interest points accurately point to the edges and corners of the image.
        
            \newpage
            \item 
            The selected descriptor is SURF (Speed Up Robust Feature).
            
            \textbf{Key point Detection}
            
            The keypoint detection algorithm is similar to SIFT, but the blob detectors are different.
                       
            In SURF, key points are detected using Box Filters that approximates LoGs.
            These Box Filters are easier to calculate using the Integral images. Integral images are sum of all the intensities of the image $ I_{\Sigma} (X) = \sum_{i = 0}^{i \leq x} \sum_{j = 0}^{j \leq y} I(i, j) $.
            
            The blob detector used in SURF is Hessian matrix
            
            \begin{equation}
            H (p, \sigma) = 
            \begin{bmatrix}
                L_{xx} (p, \sigma) & L_{xy} (p, \sigma)\\
                L_{yx} (p, \sigma) & L_{yy} (p, \sigma)
            \end{bmatrix}
            \end{equation}
            
            where $ L_{xx}(p,\sigma )$ etc. are the convolution of the second-order derivative of gaussian with the image $I(x,y)$ at the point $p$.
            
            The determinant of the Hessian matrix is used as a measure of local change around the point and points are chosen where this determinant is maximal
            
            
            \textbf{Key point Descriptor}
            
            The keypoint descriptor algorithm is also similar to SIFT.
            
            1. fix a reproducible
            orientation based on information from a circular region around the interest point.
            
            This is done by calculating the Haar-wavelet responses
            in $x$ and $y$ direction, and this in a circular neighbourhood of
            radius $6s$ around the interest point, with $s$ the scale at which the interest point was detected
            
            2. construct a square region aligned to the selected orientation, and extract the SURF descriptor from it. These two steps are now explained in turn.
            
            This is done by splitting the region up regularly into smaller 4 × 4 square sub-regions. For each sub-region, we compute a few simple features at 5×5 regularly spaced sample points. Then the features are weighted with Gaussian according to their location.
            
        
    	\end{enumerate}
    
        
        
    	
    \end{homeworkProblem}


    \clearpage
    %=========================================================
    %---------------------------------------------------------------------------------
    %	PROBLEM 3: 
    %---------------------------------------------------------------------------------
    %=========================================================
    \begin{homeworkProblem}
        
        \begin{enumerate}
            \item
            Gaussian:
            \begin{align*}
            G(x, y, \sigma) = \frac{1}{\sqrt{2\pi \sigma^{2}}} e^{-\frac{x^2 + y^2}{2 \sigma^2}}
            \end{align*}
            
            Gaussian First derivative w.r.t x:
            \begin{align*}
            \frac{\partial G(x, y, \sigma)}{\partial x} &= -\frac{1}{\sqrt{2\pi \sigma}} \frac{x}{\sigma^2} e^{-\frac{x^2 + y^2}{2 \sigma^2}}
            \end{align*}
            
            Gaussian Second derivative w.r.t x:
            \begin{align*}
            \frac{\partial^2 G(x, y, \sigma)}{\partial x^2} &= -\frac{1}{2\pi \sigma^2} (\frac{x^2}{\sigma^4} e^{-\frac{x^2 + y^2}{2 \sigma^2}} - \frac{1}{\sigma^2} e^{-\frac{x^2 + y^2}{2 \sigma^2}}) \\
            &= \frac{1}{2\pi \sigma^2} \frac{x^2 - \sigma^2}{\sigma^4} e^{-\frac{x^2 + y^2}{2 \sigma^2}}
            \end{align*}
            
            Similarly, we can derive the Gaussian Second derivative w.r.t y:
            \begin{align*}
            \frac{\partial^2 G(x, y, \sigma)}{\partial y^2} &= \frac{1}{2\pi \sigma^2} \frac{y^2 - \sigma^2}{\sigma^4} e^{-\frac{x^2 + y^2}{2 \sigma^2}}
            \end{align*}
            
            Laplacian of Gaussian:
            \begin{align*}
            \triangledown^2 G(x, y, \sigma) &= \frac{\partial^2 G(x, y, \sigma)}{\partial x^2} + \frac{\partial^2 G(x, y, \sigma)}{\partial y^2}\\
            &= \frac{1}{2\pi \sigma^2} \frac{1}{\sigma^4} e^{-\frac{x^2 + y^2}{2 \sigma^2}} (x^2 + y^2 - 2\sigma^2)\\
            &=-\frac{x^2 + y^2 - 2\sigma^2}{2 \pi \sigma^6} e^{-\frac{x^2 + y^2}{2 \sigma^2}} \\
            &= -\frac{1}{\pi \sigma^4} (1 - \frac{x^2 + y^2}{\sigma^2}) e^{-\frac{x^2 + y^2}{2 \sigma^2}} 
            \end{align*}
            
            The Laplacian of Gaussian is NOT separable because it can not be separated into the product of two vectors.
            
           
        \item 
            Difference of Gaussian
            
            \begin{align*}
            G(x, y, \sigma_1) - G(x, y, \sigma_2) &= \frac{1}{\sqrt{2\pi \sigma_1^{2}}} e^{-\frac{x^2 + y^2}{2 \sigma_1^2}} - \frac{1}{\sqrt{2\pi \sigma_2^{2}}} e^{-\frac{x^2 + y^2}{2 \sigma_2^2}}\\
            &= \frac{1}{\sqrt{2\pi }} (\dfrac{1}{\sigma_1} e^{-\frac{x^2 + y^2}{2 \sigma_1^2}} -  \dfrac{1}{\sigma_2} e^{-\frac{x^2 + y^2}{2 \sigma_2^2}})
            \end{align*}
            
            Setting $\sigma_1 = k \sigma_2$,
            
            \begin{align*}
            G(x, y, \sigma_1) - G(x, y, \sigma_2) &= \frac{1}{\sqrt{2\pi }} (\dfrac{1}{k\sigma_2} e^{-\frac{x^2 + y^2}{2 k^2 \sigma_2^2}} -  \dfrac{1}{\sigma_2} e^{-\frac{x^2 + y^2}{2 \sigma_2^2}})\\
            &= -\frac{1}{\sqrt{2\pi }} (1 - \dfrac{1}{k} e^{-\dfrac{(x^2 + y^2)}{k^2}}) e^{-\frac{x^2 + y^2}{2 \sigma_2^2}}
            \end{align*}
            
            Note that this has similar form with the Laplacian of Gaussian.
            
            As the difference between $\sigma_1$ and $\sigma_2$ gets larger, $k$ gets larger as well. If $k$ gets either too large or too little, it will not be able to approximate LoG well.
            
            
            
        \end{enumerate}
        
    \end{homeworkProblem}


        \clearpage
    %=========================================================
    %---------------------------------------------------------------------------------
    %	PROBLEM 4: 
    %---------------------------------------------------------------------------------
    %=========================================================
    \begin{homeworkProblem}
        
        See \textit{question\_4.py} for implementations. \textbf{The SIFT algorithm being used is implemented in OpenCV}
                
        \begin{enumerate}
            %	Part a: 
            \item
            
            The extracted SIFT feature points for sample1 and sample2 are shown in Figure \ref{fig:4.1}.
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_1_sample1_img.jpg}
                    \centering
                    \caption{Sample1}
                    \label{fig:4.1.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_1_sample2_img.jpg}
                    \centering
                    \caption{Sample2}
                    \label{fig:4.1.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:4.1}
            \end{figure}
        
            %	Part b: 
            \item 
            
            The top 10 feature points calculated using L2 norm and ratio threshold of 0.8 are labeled (white dots) on both sample1 and sample2 shown in Figure \ref{fig:4.2}.
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_2_marked_sample_1_L2.jpg}
                    \centering
                    \caption{Sample1 feature points}
                    \label{fig:4.2.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_2_marked_sample_2_L2.jpg}
                    \centering
                    \caption{Sample2 feature points}
                    \label{fig:4.2.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:4.2}
            \end{figure}
        
            \newpage
            The connected image is shown bellow
            
            \begin{figure}[!htb]
                \includegraphics[width=0.75\linewidth]{images/question_4/4_2_connected_L2.png}
                \centering
                \caption{}
                \label{fig:4.2.3}
            \end{figure}
        

            By testing with different threshold values, the following graph was produced. This is reasonable because as we loosen our restrictions, more and more points will be matched between the two images.
            
            \begin{figure}[!htb]
                \includegraphics[width=0.75\linewidth]{images/question_4/4_2_match_vs_threshold.png}
                \centering
                \caption{}
                \label{fig:4.2.4}
            \end{figure}
            
            %	Part c:
            \newpage
            \item 
            
            The top 10 feature points calculated using L1 norm and ratio threshold of 0.8 are labeled (white dots) on both sample1 and sample2 shown in Figure \ref{fig:4.3.1}.
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_2_marked_sample_1_L1.jpg}
                    \centering
                    \caption{Sample1 feature points}
                    \label{fig:4.3.1.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_2_marked_sample_2_L1.jpg}
                    \centering
                    \caption{Sample2 feature points}
                    \label{fig:4.3.1.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:4.3.1}
            \end{figure}
            
            The connected image is shown bellow
            
            \begin{figure}[!htb]
                \includegraphics[width=0.75\linewidth]{images/question_4/4_2_connected_L1.png}
                \centering
                \caption{}
                \label{fig:4.3.1.3}
            \end{figure}
            
            
            The top 10 feature points calculated using L3 norm and ratio threshold of 0.8 are labeled (white dots) on both sample1 and sample2 shown in Figure \ref{fig:4.3.2}.
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_2_marked_sample_1_L3.jpg}
                    \centering
                    \caption{Sample1 feature points}
                    \label{fig:4.3.2.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_2_marked_sample_2_L3.jpg}
                    \centering
                    \caption{Sample2 feature points}
                    \label{fig:4.3.2.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:4.3.2}
            \end{figure}
        
            The connected image is shown bellow
            
            \begin{figure}[!htb]
                \includegraphics[width=0.75\linewidth]{images/question_4/4_2_connected_L3.png}
                \centering
                \caption{}
                \label{fig:4.3.2.3}
            \end{figure}
        
            We can see that the result for L1 is better because it contains more corners
            
            %	Part d:
            \newpage
            
            \item 
            The marked feature points for the noisy images are shown bellow:
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_4_sample1_img.jpg}
                    \centering
                    \caption{Sample1 feature points}
                    \label{fig:4.4.1.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_4_sample2_img.jpg}
                    \centering
                    \caption{Sample2 feature points}
                    \label{fig:4.4.1.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:4.4.1}
            \end{figure}
            
            \newpage
            The top 10 feature points of the noisy image calculated using L2 norm and ratio threshold of 0.8 are labeled (white dots) on both sample1 and sample2 shown in Figure \ref{fig:4.3.1}.
            
            We can clearly see that adding noise to the image drastically changes the detected feature points.
            
            The detected points are mostly concentrated on the picture with black background because due to noise and image clipping, there are more white pixels and more likely to be detected as corners.
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_4_marked_sample_1_L2.jpg}
                    \centering
                    \caption{Sample1 feature points}
                    \label{fig:4.4.2.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_4_marked_sample_2_L2.jpg}
                    \centering
                    \caption{Sample2 feature points}
                    \label{fig:4.4.2.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:4.4.2}
            \end{figure}
        
            See the connected image below
            \begin{figure}[!htb]
                \includegraphics[width=0.75\linewidth]{images/question_4/4_4_connected_L2.png}
                \centering
                \caption{}
                \label{fig:4.4.4}
            \end{figure}
            
            \newpage
            By testing with different threshold values, the following graph was produced. This is reasonable because as we loosen our restrictions, more and more points will be matched between the two images.
            
            Comparing to the graph produced in part b, this graph is steeper. This means that we are less likely to produce detect the feature points.
            
            \begin{figure}[!htb]
                \includegraphics[width=0.75\linewidth]{images/question_4/4_4_match_vs_threshold.png}
                \centering
                \caption{}
                \label{fig:4.4.3}
            \end{figure}
            
            
            \newpage
            %	Part e:
            \item 
            See detected interest points and the images in the below. 
            
            The approach to perform SIFT on a colored image is to separately generate the key points and descriptors for each color channel, then stack them together. Then we calculate the minimum distance between two images using the descriptors. We compare the distances between all color channels and pick the minimum one.
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_5_marked_ct.png}
                    \centering
                    \caption{color template feature points}
                    \label{fig:4.5.1.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_4/4_5_marked_cs.png}
                    \centering
                    \caption{color search feature points}
                    \label{fig:4.5.1.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:4.5.1}
            \end{figure}
        
            See the connected image below
            \begin{figure}[!htb]
                \includegraphics[width=0.75\linewidth]{images/question_4/4_5_connected_L2.png}
                \centering
                \caption{}
                \label{fig:4.5.2}
            \end{figure}
        
            \newpage
        
            Below is the match count vs threshold plot. In this question, the size of data (pixel) is not as plenty as the previous questions, so the curve is not fully shown. However, the relationship between the threshold and the match count is still positive. I.e. the looser we threshold the ratio, the more matches we will get.
        
            \begin{figure}[!htb]
                \includegraphics[width=0.75\linewidth]{images/question_4/4_5_match_vs_threshold.png}
                \centering
                \caption{}
                \label{fig:4.5.3}
            \end{figure}
            
        \end{enumerate}
        
        \end{homeworkProblem}

	
	
	%=========================================================
	%---------------------------------------------------------------------------------
	%	END
	%---------------------------------------------------------------------------------
	%=========================================================
	
\end{document}
