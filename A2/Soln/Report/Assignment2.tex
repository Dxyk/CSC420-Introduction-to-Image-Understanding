% Template credit to University of Toronto CSC411 and CSC320
%------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{subcaption}
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
% Below are optional packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\chead{\hmwkClass\ : \hmwkTitle} % Top center head
%\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs


%------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
	%\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
	%\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
	%\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
	%\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems
\setcounter{homeworkProblemCounter}{0}

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
	\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
	\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
	\section{\homeworkProblemName} % Make a section in the document with the custom problem count
	\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
	\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
	\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
	\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
	\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
	\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
	\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}


%=================================================================

%------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Assignment\ 2} % Assignment title
\newcommand{\hmwkClass}{CSC420} % Course/class
\newcommand{\hmwkAuthorName}{Xiangyu Kong, kongxi16} % Your name

%------------------------------------------------------------------------------------
%	TITLE PAGE
%------------------------------------------------------------------------------------

\title{
	\vspace{2in}
	\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
	%	\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
	\vspace{0.1in}
	\vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}

% Insert date here if you want it to appear below your name
\date{\today} 

%------------------------------------------------------------------------------------

\begin{document}
	
	\maketitle
	\clearpage
	
	%=========================================================
	%---------------------------------------------------------------------------------
	%	PROBLEM 1: 
	%---------------------------------------------------------------------------------
	%=========================================================
	\begin{homeworkProblem}
		
        See \textit{question\_1.py} for implementation.
        
		\begin{enumerate}
			
			\item 
			
			The result of applying linear interpolation to up-sample the image by 4 times are shown in Figure \ref{fig:1.1}.
            
            Figure \ref{fig:1.1.1} shows the first round of convolution along the first axis. 
            
            Figure \ref{fig:1.1.2} shows the second round of convolution along the second axis on top of the result of the first round.
            
            Comparing to the original image, the up-sampled image maintains most of the information because the images look alike.
            
            \begin{figure}[!htb]
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[height=\linewidth, width=\linewidth]{images/question_1/1_1_1.jpg}
                    \centering
                    \caption{First round}
                    \label{fig:1.1.1}
                \end{subfigure}
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/question_1/1_1_2.jpg}
                    \centering
                    \caption{Second Round}
                    \label{fig:1.1.2}
                \end{subfigure}
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/orig/bee.jpg}
                    \centering
                    \caption{Original Image}
                    \label{fig:1.1.3}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:1.1}
            \end{figure}
        
            To achieve the same operation (up-sampling by a factor of 4), we can multiply the 1-dimensional filter by itself to get a 2-dimensional filter. This filter will be separable, and will produce the same result as convolving with the 1-dimensional filter twice on different directions.
            
            In this specific case of up-sampling by a factor of 4, we calculate that
            
            \begin{align*}
                h & = 
                \begin{bmatrix}
                0.25 & 0.5 & 0.75 & 1 & 0.75 & 0.5 & 0.25
                \end{bmatrix} \\
                h \times h^{T} & = 
                \begin{bmatrix}
                0.0625 & 0.125 & 0.1875 & 0.25 & 0.1875 & 0.125 & 0.0625 \\
                0.125 & 0.25 & 0.375 & 0.5 & 0.375 & 0.25 & 0.125 \\
                0.1875 & 0.375 & 0.5625 & 0.75 & 0.5625 & 0.375 &0.1875\\
                0.25 & 0.5 & 0.75 & 1 &	0.75 & 0.5 & 0.25\\
                0.1875 & 0.375 & 0.5625 & 0.75 & 0.5625 & 0.375 &0.1875\\
                0.125  & 0.25 & 0.375 &	0.5 & 0.375 & 0.25 & 0.125\\
                0.0625 & 0.125 & 0.1875 & 0.25 & 0.1875	& 0.125	& 0.0625
                \end{bmatrix} \\
            \end{align*}

            \newpage
            \item
            
            The generalized two dimensional linear interpolation reconstruction filter is 
            
            \begin{align*}
            h & = 
            \begin{bmatrix}
            \frac{1}{d} & \dots & \frac{d-1}{d} & 1 & \frac{d-1}{d} & \dots & \frac{1}{d}
            \end{bmatrix} \\
            h \times h^{T} & = 
            \begin{bmatrix}
            \frac{1}{d}^2 & \dots & \frac{d-1}{d} \times \frac{1}{d} & 1 \times \frac{1}{d} & \frac{d-1}{d} \times \frac{1}{d} & \dots & \frac{1}{d}^2 \\
            \frac{d-1}{d} \times \frac{1}{d} & \ddots & \dots & \dots & \dots & \dots & \vdots \\
            \vdots & \dots & \dots & 1 &	\dots & \dots & \vdots\\
            \frac{d-1}{d} \times \frac{1}{d} & \dots & \dots & \dots & \dots	& \dots	& \frac{d-1}{d}^2
            \end{bmatrix} \\
            \end{align*}
            
            Since this is a separable filter (composed of $h \times h^T$), it is equivalent of applying the 1D linear interpolation filter twice in both direction.
            
            The results of the 2D linear interpolation filter convolution is shown in Figure \ref{fig:1.2.1}. Comparing to the result of applying 1D linear interpolation filter twice in two directions (Figure \ref{fig:1.2.2}), the results do not have any difference. 
            
            \begin{figure}[!htb]
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/question_1/1_2.jpg}
                    \centering
                    \caption{2D Filter}
                    \label{fig:1.2.1}
                \end{subfigure}
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/question_1/1_1_2.jpg}
                    \centering
                    \caption{1D Filter}
                    \label{fig:1.2.2}
                \end{subfigure}
                \begin{subfigure}{.3\textwidth}
                    \includegraphics[width=\linewidth]{images/orig/bee.jpg}
                    \centering
                    \caption{Original Image}
                    \label{fig:1.2.3}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:1.2}
            \end{figure}
			
		\end{enumerate}
	
	\end{homeworkProblem}

    \clearpage
    %=========================================================
    %---------------------------------------------------------------------------------
    %	PROBLEM 2: 
    %---------------------------------------------------------------------------------
    %=========================================================
    \begin{homeworkProblem}
    	
        See \textit{question\_2.py} for implementations.
        
    	\begin{enumerate}
    		\item
            The outputs of the corner detection functions are listed in Figure \ref{fig:2.1}.
            
            After tuning with different alpha values, $\alpha = 0.06$ was picked because it produced the least amount of noise.
            
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_1_Harris.jpg}
                \centering
                \caption{Harris corner detection}
                \label{fig:2.1.1}
            \end{figure}
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_1_Brown.jpg}
                \centering
                \caption{Brown corner detection}
                \label{fig:2.1.2}
            \end{figure}
            
            The only way for us to calculate the R scores without using determinant or trace is to calculate the eigenvalues for each window's error term. However, this is extremely computationally heavy and does yield a better result than computing the trace and determinant.
            
            \item
            
            First we rotate the original image to produce Figure \ref{fig:2.2.1}
            
            \begin{figure}[!htb]
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_2/2_2_rotated_img.jpg}
                    \centering
                    \caption{Rotated image}
                    \label{fig:2.2.1}
                \end{subfigure}
                \begin{subfigure}{.45\textwidth}
                    \includegraphics[width=\linewidth]{images/question_2/2_2_orig_img.jpg}
                    \centering
                    \caption{Original Image}
                    \label{fig:2.2.2}
                \end{subfigure}
                \centering
                \caption{}
                \label{fig:2.2}
            \end{figure}
        
            By applying Harris corner detection to the rotated image, we get Figure \ref{fig:2.2.3}. We can see that the detected corners are also rotated.
        
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_2_rotated_R.jpg}
                \centering
                \caption{Rotated Haris corner detection}
                \label{fig:2.2.3}
            \end{figure}
            
            \newpage
        
            By rotating the detected corners, we get the following Figure \ref{fig:2.2.4}.
            
            To prove that the detected points are also rotated by the same angle, we count the number of detected corners in the rotated image ($num\_total\_rotated$). Then we also count the number of corners in the original image corresponding to the corners in the rotated image ($num\_match$). Then we take the fraction of those two $\dfrac{num\_match}{num\_total\_rotated}$. The result was $99\%$ which is sufficient to prove that the detected corners are the same.
            
            Note that we didn't count the total number of detected corner in the original image ($num\_total\_original$) and compare it with the number of corners detected in the rotated image because rotating the image will caused some information loss, and this measurement won't be accurate.
            
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_2_rerotated_R.jpg}
                \centering
                \caption{Un-rotate detected corners}
                \label{fig:2.2.4}
            \end{figure}
        
            \newpage
            \item 
            The generated results are shown in Figure \ref{fig:2.3.1}.
            
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_2_rerotated_R.jpg}
                \centering
                \caption{Interest points}
                \label{fig:2.3.1}
            \end{figure}
        
            By circling out the interest points on the original image, we get Figure \ref{fig:2.3.2}.
            
            \begin{figure}[!htb]
                \includegraphics[width=\linewidth]{images/question_2/2_2_rerotated_R.jpg}
                \centering
                \caption{Image with interest points}
                \label{fig:2.321}
            \end{figure}
        
        
            \newpage
            \item 
            The selected descriptor is SURF (Speed Up Robust Feature).
            
            \textbf{Key point Detection}
            
            In SURF, key points are detected using Box Filters that approximates LoGs.
            These Box Filters are easier to calculate using the Integral images. Integral images are sum of all the intensities of the image $ I_{\Sigma} (X) = \sum_{i = 0}^{i \leq x} \sum_{j = 0}^{j \leq y} I(i, j) $.
            
            The blob detector used in SURF is Hessian matrix
            
            \begin{equation}
            H (p, \sigma) = 
            \begin{bmatrix}
                L_{xx} (p, \sigma) & L_{xy} (p, \sigma)\\
                L_{yx} (p, \sigma) & L_{yy} (p, \sigma)
            \end{bmatrix}
            \end{equation}
            
            where $ L_{xx}(p,\sigma )$ etc. is the convolution of the second-order derivative of gaussian with the image $I(x,y)$ at the point $p$.
            
            The determinant of the Hessian matrix is used as a measure of local change around the point and points are chosen where this determinant is maximal
            
            
            \textbf{Key point Descriptor}
            
            In order to invariant to image rotation, we identify a reproducible orientation for the interest points. Because of that, first calculate
            the Haar wavelet responses in x and y direction within a circular neighbourhood of radius 6s around the interest point, with scale
            s (sampling step is depend on s) at which the interest point was detected. The size of wavelet which is scale depended and its side
            length is 4s. 
            
            Once the wavelet responses are calculated and weighted with a Gaussian σ=2s centered at the interest point. The responses
            are represented as points in a space with the horizontal response strength along the abscissa and the vertical response strength along
            the ordinate. Find maximum the sum of all responses which is wavelet response in every sliding window (π/3 window orientation)
            (see figure 4). The horizontal and vertical responses within the window are summed. From these two horizontal and vertical,
            summed responses then yield a local orientation vector. The orientation of the interest point can be defined by finding the longest
            such vector over all windows.
            
            To extract the descriptor, square region which size is 20s are constructed on interested points. Examples of such square
            regions are illustrated in figure 5
            
            The wavelet responses dx and dy are summed up over each sub-region and form a first set of entries in the feature vector.
            In order to bring in information about the polarity of the intensity changes, extract the sum of the absolute values of the responses,
            |dx| and |dy|, each sub-region has a four-dimensional descriptor vector V for its underlying intensity structure V =
            (∑ dx
            , ∑ dy
            , ∑ |dx
            | , ∑ |dx
            |). Concatenating this for all, 4 x 4 sub-regions, and this results in a descriptor vector of length is 64.
            The wavelet responses are invariant to a bias in illumination (offset) and Invariance to contrast (a scale factor) is achieved by
            turning the descriptor into a unit vector.
            
        
    	\end{enumerate}
    
        
        
    	
    \end{homeworkProblem}


    \clearpage
    %=========================================================
    %---------------------------------------------------------------------------------
    %	PROBLEM 3: 
    %---------------------------------------------------------------------------------
    %=========================================================
    \begin{homeworkProblem}
        
        \begin{enumerate}
            \item
            Gaussian:
            \begin{align*}
            G(x, y, \sigma) = \frac{1}{\sqrt{2\pi \sigma^{2}}} e^{-\frac{x^2 + y^2}{2 \sigma^2}}
            \end{align*}
            
            Gaussian First derivative w.r.t x:
            \begin{align*}
            \frac{\partial G(x, y, \sigma)}{\partial x} &= -\frac{1}{\sqrt{2\pi \sigma}} \frac{x}{\sigma^2} e^{-\frac{x^2 + y^2}{2 \sigma^2}}
            \end{align*}
            
            Gaussian Second derivative w.r.t x:
            \begin{align*}
            \frac{\partial^2 G(x, y, \sigma)}{\partial x^2} &= -\frac{1}{2\pi \sigma^2} (\frac{x^2}{\sigma^4} e^{-\frac{x^2 + y^2}{2 \sigma^2}} - \frac{1}{\sigma^2} e^{-\frac{x^2 + y^2}{2 \sigma^2}}) \\
            &= \frac{1}{2\pi \sigma^2} \frac{x^2 - \sigma^2}{\sigma^4} e^{-\frac{x^2 + y^2}{2 \sigma^2}}
            \end{align*}
            
            Similarly, we can derive the Gaussian Second derivative w.r.t y:
            \begin{align*}
            \frac{\partial^2 G(x, y, \sigma)}{\partial y^2} &= \frac{1}{2\pi \sigma^2} \frac{y^2 - \sigma^2}{\sigma^4} e^{-\frac{x^2 + y^2}{2 \sigma^2}}
            \end{align*}
            
            Laplacian of Gaussian:
            \begin{align*}
            \triangledown^2 G(x, y, \sigma) &= \frac{\partial^2 G(x, y, \sigma)}{\partial x^2} + \frac{\partial^2 G(x, y, \sigma)}{\partial y^2}\\
            &= \frac{1}{2\pi \sigma^2} \frac{1}{\sigma^4} e^{-\frac{x^2 + y^2}{2 \sigma^2}} (x^2 + y^2 - 2\sigma^2)\\
            &=-\frac{x^2 + y^2 - 2\sigma^2}{2 \pi \sigma^6} e^{-\frac{x^2 + y^2}{2 \sigma^2}} \\
            &= -\frac{1}{\pi \sigma^4} (1 - \frac{x^2 + y^2}{\sigma^2}) e^{-\frac{x^2 + y^2}{2 \sigma^2}} 
            \end{align*}
            
            The Laplacian of Gaussian is NOT separable because it can not be separated into the product of two vectors.
            
           
        \item 
            Difference of Gaussian
            
            \begin{align*}
            G(x, y, \sigma_1) - G(x, y, \sigma_2) &= \frac{1}{\sqrt{2\pi \sigma_1^{2}}} e^{-\frac{x^2 + y^2}{2 \sigma_1^2}} - \frac{1}{\sqrt{2\pi \sigma_2^{2}}} e^{-\frac{x^2 + y^2}{2 \sigma_2^2}}
            \end{align*}
            
            % TODO
            
            
        \end{enumerate}
        
    \end{homeworkProblem}


        \clearpage
    %=========================================================
    %---------------------------------------------------------------------------------
    %	PROBLEM 4: 
    %---------------------------------------------------------------------------------
    %=========================================================
    \begin{homeworkProblem}
        
        \begin{enumerate}
            \item
            
        \end{enumerate}
        
        \end{homeworkProblem}

	
	
	%=========================================================
	%---------------------------------------------------------------------------------
	%	END
	%---------------------------------------------------------------------------------
	%=========================================================
	
\end{document}
