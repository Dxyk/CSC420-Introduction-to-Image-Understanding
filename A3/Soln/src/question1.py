from torch import nn
from torch.utils.data import DataLoader

from UNet import UNet
from load_data import *
from train_network import AttrDict, train


def get_data_loaders(args: AttrDict, all_transforms: transforms = None) -> \
        Tuple[DataLoader, DataLoader]:
    """
    Get The data loaders for the training and testing data

    :param args: the arguments for the network
    :param all_transforms: all the possible transformations on data
    :return: the data loader
    """
    train_dataset = CatDataset(Path(args.src_dir).joinpath(TRAIN),
                               all_transforms=all_transforms,
                               is_train=True,
                               sample_type=args.sample_type)
    test_dataset = CatDataset(Path(args.src_dir).joinpath(TEST),
                              all_transforms=all_transforms,
                              is_train=False,
                              sample_type=args.sample_type)
    train_data_loader = DataLoader(train_dataset, batch_size=args.batch_size,
                                   shuffle=True)
    test_data_loader = DataLoader(test_dataset, batch_size=args.batch_size,
                                  shuffle=True)
    return train_data_loader, test_data_loader


# ==================== Loss Functions ====================
def dice_loss(prediction: Tensor, label: Tensor) -> Tensor:
    """
    The dice loss function

    :param prediction: the prediction generated by network
    :param label: the true value
    :return: the dice loss
    """
    smooth = 1.
    pred_flat = prediction.view(-1)
    lab_flat = label.view(-1)
    intersection = (pred_flat * lab_flat).sum()
    return 1 - ((2. * intersection + smooth) /
                (pred_flat.sum() + lab_flat.sum() + smooth))


def bce_loss(prediction: Tensor, label: Tensor) -> Tensor:
    """
    The Binary Cross Entropy Loss

    :param prediction: the prediction generated by network
    :param label: the true value
    :return: the BCE Loss
    """
    prediction_flat = prediction.view(-1)
    label_flat = label.view(-1)
    return nn.BCELoss()(prediction_flat, label_flat)


# ==================== Part 1 ====================
def part1() -> None:
    """ Part 1 """
    print("{0} Part 1 {0}".format("=" * 10))
    # =============== Args ===============
    args = AttrDict()
    args_dict = {
        'src_dir': CAT_DATA,
        'kernel': 3,
        'num_filters': 64,
        'learn_rate': 1e-3,
        'batch_size': 5,
        'epochs': 25,
        'output_name': 'unet',
        'sample_type': 'cat',
    }
    args.update(args_dict)

    # =============== Train with BCE ===============
    print("{0} Training {1} {0}".format("=" * 5, "bce"))
    train_data_loader, test_data_loader = get_data_loaders(args)
    args.checkpoint = CHECKPOINT_PATH + "1_1_bce.pt"
    trained_network = train(args, bce_loss, train_data_loader, test_data_loader)
    print("{0} Done {0}".format("=" * 5))

    # =============== Train with Dice ===============
    print("{0} Training {1} {0}".format("=" * 5, "dice"))
    train_data_loader, test_data_loader = get_data_loaders(args)
    args.checkpoint = CHECKPOINT_PATH + "1_1_dice.pt"
    trained_network = train(args, dice_loss, train_data_loader,
                            test_data_loader)
    print("{0} Done {0}".format("=" * 5))

    print("{0} Part 1 Done {0}".format("=" * 10))


# ==================== Part 2 ====================
def part2() -> None:
    """ Part 2 """
    print("{0} Part 2 {0}".format("=" * 10))
    # =============== Args ===============
    args = AttrDict()
    args_dict = {
        'src_dir': CAT_DATA,
        'kernel': 3,
        'num_filters': 64,
        'learn_rate': 1e-3,
        'batch_size': 5,
        'epochs': 25,
        'output_name': 'unet',
        'sample_type': 'cat',
    }
    args.update(args_dict)

    # =============== Transforms ===============
    all_transforms = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.RandomRotation([15, 60]),
        transforms.RandomResizedCrop(STANDARD_DIMS),
        transforms.ToTensor()
    ])

    # =============== Train with Dice ===============
    print("{0} Training {1} {0}".format("=" * 5, "dice"))
    train_data_loader, test_data_loader = \
        get_data_loaders(args, all_transforms=all_transforms)
    args.checkpoint = CHECKPOINT_PATH + "1_2_dice_transforms.pt"

    trained_network = train(args, dice_loss, train_data_loader,
                            test_data_loader)
    print("{0} Done {0}".format("=" * 5))

    print("{0} Part 2 Done {0}".format("=" * 10))


# ==================== Part 3 ====================
def part3() -> None:
    """ Part 3 """
    print("{0} Part 3 {0}".format("=" * 10))
    # =============== Args ===============
    args = AttrDict()
    args_dict = {
        'src_dir': MEMBRANE_DATA,
        'kernel': 3,
        'num_filters': 64,
        'learn_rate': 1e-3,
        'batch_size': 5,
        'epochs': 25,
        'seed': 0,
        'output_name': 'unet',
        'sample_type': 'membrane',
    }
    args.update(args_dict)

    # =============== Training on Membrane with Dice ===============
    print("{0} Training {1} {0}".format("=" * 10, "membrane"))
    train_data_loader, test_data_loader = get_data_loaders(args)
    args.checkpoint = CHECKPOINT_PATH + "1_3_dice_membrane.pt"
    trained_unet = train(args, dice_loss, train_data_loader, test_data_loader)
    print("{0} Done {0}".format("=" * 10))

    # =============== Load pre-trained model ===============
    print("{0} Loading Pre-trained {0}".format("=" * 10))
    pre_trained_unet = UNet(num_channels=1, num_classes=2, num_filters=64)
    loaded_weights = torch.load(CHECKPOINT_PATH +
                                "/1_3_dice_membrane.pt")
    pre_trained_unet.load_state_dict(loaded_weights)
    pre_trained_unet.eval()
    print("{0} Done {0}".format("=" * 10))

    # TODO: set this to middle layer
    # reset the necessary layers
    pre_trained_unet.out_conv = nn.Conv2d(64, 2, 1)

    # =============== Training on pre-trained on Cat with Dice ===============
    print("{0} Training {1} {0}".format("=" * 10, "cat"))
    train_data_loader, test_data_loader = get_data_loaders(args)
    args.sample_type = 'cat'
    args.src_dir = CAT_DATA
    args.checkpoint = CHECKPOINT_PATH + "1_3_dice_cat.pt"

    trained_network = train(args, dice_loss, train_data_loader,
                            test_data_loader, model=pre_trained_unet)
    print("{0} Done {0}".format("=" * 10))

    print("{0} Part 3 Done {0}".format("=" * 10))


def main() -> None:
    """ Main """
    part1()
    part2()
    part3()


if __name__ == '__main__':
    # ==================== Main ====================

    main()
