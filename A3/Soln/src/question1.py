from torch import nn, optim  # using torch.Tensor is annoying
from torch.utils.data import DataLoader

from UNet import UNet
from load_data import *


def dice_loss(prediction, label):
    """
    The dice loss function

    :param prediction: the prediction generated by network
    :param label: the true value
    :return: the dice loss
    """
    smooth = 1.
    pred_flat = prediction.view(-1)
    lab_flat = label.view(-1)
    intersection = (pred_flat * lab_flat).sum()
    return 1 - ((2. * intersection + smooth) /
                (pred_flat.sum() + lab_flat.sum() + smooth))


def bce_loss(prediction, label):
    """
    The Binary Cross Entropy Loss

    :param prediction: the prediction generated by network
    :param label: the true value
    :return: the BCE Loss
    """
    prediction_flat = prediction.view(-1)
    label_flat = label.view(-1)
    return nn.BCELoss()(prediction_flat, label_flat)


def train(criterion, save_model=True):
    unet_model = UNet().float()

    if use_gpu:
        unet_model = unet_model.cuda()

    optimizer = optim.Adam(unet_model.parameters(), lr=alpha)

    train_losses, test_losses = [], []
    for e in range(epochs):
        unet_model.train()
        running_loss = 0
        for images, labels in train_data_loader:
            if use_gpu:
                images, labels = images.cuda(), labels.cuda()
            prediction = unet_model(images.float())

            loss = criterion(prediction, labels.float())
            running_loss += loss.item()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        else:
            test_loss = 0
            accuracy = 0
            # Turn off gradients for validation, saves memory and computations
            with torch.no_grad():
                for images, labels in test_data_loader:
                    images = images.type(torch.FloatTensor)
                    labels = labels.type(torch.FloatTensor)
                    if use_gpu:
                        images, labels = images.cuda(), labels.cuda()
                    log_ps = unet_model(images)
                    test_loss += criterion(log_ps, labels)

                    ps = torch.exp(log_ps)
                    top_p, top_class = ps.topk(1, dim=1)
                    labeled = labels[:, 1, :, :]
                    equals = labeled.view(*top_class.shape)
                    accuracy += torch.mean(equals.type(torch.FloatTensor))

            train_losses.append(running_loss / len(train_data_loader))
            test_losses.append(test_loss / len(test_data_loader))

            print("Epoch: {}/{}.. ".format(e + 1, epochs))
            print("Training Loss: {:.3f}.. ".format(
                running_loss / len(train_data_loader)))
            print("Test Loss: {:.3f}.. ".format(
                test_loss / len(test_data_loader)))
            print("Test Accuracy: {:.3f}".format(
                accuracy / len(test_data_loader)))
            print("Training loss: {}".format(
                running_loss / len(train_data_loader)))

        if save_model:
            criterion_name = "BCE" if criterion == bce_loss else "Dice"
            target_path = Path(CHECKPOINT_PATH).joinpath(
                'CP_{}_{}.pth'.format(criterion_name, e + 1))
            torch.save(unet_model.state_dict(), str(target_path))
            print('Checkpoint {}_{} saved !'.format(criterion_name, e + 1))


def part1():
    """ Part 1 """
    train(bce_loss)
    train(dice_loss)


def main():
    part1()


if __name__ == '__main__':
    # ==================== Hyper-Parameters ====================
    epochs = 15
    # set to true in colab
    use_gpu = False
    batch_size = 3
    transform = None
    alpha = 3 * 1e-4

    # ==================== Load Data ====================
    print("{0} Loading Data {0}".format("=" * 10))
    train_dataset = CatDataset(TRAIN_PATH, transform=transform, is_train=True)
    test_dataset = CatDataset(TEST_PATH, transform=transform, is_train=False)
    train_data_loader = DataLoader(train_dataset, batch_size=batch_size,
                                   shuffle=True)
    test_data_loader = DataLoader(test_dataset, batch_size=batch_size,
                                  shuffle=True)
    print("{0} Done {0}".format("=" * 10))

    # ==================== Main ====================
    main()
