from torch import nn
from torch.utils.data import DataLoader

from UNet import UNet
from load_data import *
from train_network import AttrDict, train


def get_data_loaders(args: AttrDict, all_transforms: transforms = None) -> \
        Tuple[DataLoader, DataLoader]:
    """
    Get The data loaders for the training and testing data

    :param args: the arguments for the network
    :param all_transforms: all the possible transformations on data
    :return: the data loader
    """
    test_dataset = CatDataset(Path(args.src_dir).joinpath(TEST),
                              all_transforms=all_transforms, is_train=False)
    test_data_loader = DataLoader(test_dataset, batch_size=args.batch_size,
                                  shuffle=True)
    train_dataset = CatDataset(Path(args.src_dir.joinpath(TRAIN)),
                               all_transforms=all_transforms, is_train=True,
                               is_cat=args.is_cat)
    train_data_loader = DataLoader(train_dataset, batch_size=args.batch_size,
                                   shuffle=True)
    return train_data_loader, test_data_loader


def dice_loss(prediction: Tensor, label: Tensor) -> Tensor:
    """
    The dice loss function

    :param prediction: the prediction generated by network
    :param label: the true value
    :return: the dice loss
    """
    smooth = 1.
    pred_flat = prediction.view(-1)
    lab_flat = label.view(-1)
    intersection = (pred_flat * lab_flat).sum()
    return 1 - ((2. * intersection + smooth) /
                (pred_flat.sum() + lab_flat.sum() + smooth))


def bce_loss(prediction: Tensor, label: Tensor) -> Tensor:
    """
    The Binary Cross Entropy Loss

    :param prediction: the prediction generated by network
    :param label: the true value
    :return: the BCE Loss
    """
    prediction_flat = prediction.view(-1)
    label_flat = label.view(-1)
    return nn.BCELoss()(prediction_flat, label_flat)


def part1() -> None:
    """ Part 1 """
    print("{0} Part 1 {0}".format("=" * 10))
    # ==================== Args ====================
    args = AttrDict()
    args_dict = {
        'gpu': False,
        'valid': False,
        'checkpoint': "",
        'kernel': 3,
        'num_filters': 64,
        'learn_rate': 1e-3,
        'batch_size': 5,
        'epochs': 25,
        'seed': 0,
        'plot': True,
        'output_name': 'unet',
        'visualize': False,
        'downsize_input': False,
        'is_cat': True,
    }
    args.update(args_dict)

    print("{0} Training {1} {0}".format("=" * 10, "bce"))
    train_data_loader, test_data_loader = get_data_loaders(args)
    train(args, bce_loss, train_data_loader, test_data_loader)
    print("{0} Done {0}".format("=" * 10))

    print("{0} Training {1} {0}".format("=" * 10, "dice"))
    train_data_loader, test_data_loader = get_data_loaders(args)
    train(args, dice_loss, train_data_loader, test_data_loader)
    print("{0} Done {0}".format("=" * 10))


def part2() -> None:
    # ==================== Load Data ====================
    print("{0} Part 2 {0}".format("=" * 10))
    # ==================== Args ====================
    args = AttrDict()
    args_dict = {
        'gpu': False,
        'valid': False,
        'checkpoint': "",
        'kernel': 3,
        'num_filters': 64,
        'learn_rate': 1e-3,
        'batch_size': 5,
        'epochs': 25,
        'seed': 0,
        'plot': True,
        'output_name': 'unet',
        'visualize': False,
        'downsize_input': False,
        'is_cat': True,
    }
    args.update(args_dict)
    print("{0} Loading Data {0}".format("=" * 5))
    all_transforms = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.RandomRotation([15, 60]),
        transforms.RandomResizedCrop(STANDARD_DIMS),
        transforms.ToTensor()
    ])
    train_data_loader, test_data_loader = get_data_loaders(args, all_transforms)
    train(args, dice_loss, train_data_loader, test_data_loader)


def part3() -> None:
    # ==================== Load Data ====================
    print("{0} Part 3 {0}".format("=" * 10))
    print("{0} Loading Data {0}".format("=" * 5))
    args = AttrDict()
    args_dict = {
        'gpu': True,
        'valid': False,
        'checkpoint': "",
        'kernel': 3,
        'num_filters': 64,
        'learn_rate': 1e-3,
        'batch_size': 5,
        'epochs': 25,
        'seed': 0,
        'plot': True,
        'output_name': 'unet',
        'visualize': False,
        'downsize_input': False,
        'is_cat': False,
    }
    args.update(args_dict)
    print("{0} Done Loading {0}".format("=" * 5))

    print("{0} Training {1} {0}".format("=" * 10, "bce"))
    train_data_loader, test_data_loader = get_data_loaders(args)
    trained_unet = train(args, dice_loss, train_data_loader, test_data_loader)
    torch.save(trained_unet.state_dict(),
               CHECKPOINT_PATH + "/1_3_dice_trained.pt")
    print("{0} Done {0}".format("=" * 10))

    pretrained_unet = UNet(num_channels=1, num_classes=2, num_filters=64)
    pretrained_unet.load_state_dict(
        torch.load(CHECKPOINT_PATH + "/1_3_dice_trained.pt"))
    pretrained_unet.eval()

    pretrained_unet.out_conv = nn.Conv2d(64, 2, 1)

    train_data_loader, test_data_loader = get_data_loaders(args)

    train(args, dice_loss, train_data_loader, test_data_loader,
          model=pretrained_unet)


def main():
    part1()
    part2()
    part3()


if __name__ == '__main__':
    # ==================== Main ====================

    main()
